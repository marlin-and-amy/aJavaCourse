## MidJava 3-1 Reaction Architecture [&LT;](MJ0209.md) [&GT;](MJ0302.md)
# History
## Day 4

I believe that we now have enough background to start on our main project for this mid level java course, the Gesture based Music Notation application. That last section that I showed you on I.Area was really done to manage some of the complexity that we will run into in our Music App and the next classes that we build have even more to do with it. I could just continue to work bottom up, introducing helper functions and classes, "Hey look at this neat thing that you can do," without telling you why we are building those helpers and What exactly they are going to help with. 

However, there really is an overreaching architecture that we are trying to build and you will probably have a better understanding of WHY we are building the helpers that we construct if you have some idea of where we are heading so the next few sections of this book are less code and more historical in nature telling you how some of the ideas for this Reaction Architecture evolved. So this chapter is not code at all, but an outline of what we are trying to build for our main project. 

## Gesture Applications

Way back in 1990 I was the manager of a group at Microsoft that was working on software for tablet machines. This was a type of machine that no one was making at the time but which people were predicting would be all over the place in a few years. The key feature of a tablet machine was that it would have no keyboard at all and you would do all your entry by either using a stylus or by touching the screen.

It is almost impossible for anyone alive today looking at all the current smart phones and tablets to understand that while these types of machines are legion today that there were practically no such machines back in 1990. Tablet machines were imagined but few were built and of the few that were built even fewer were sold. The excitement of 1990 was mostly gone by 1992 when the market didn't rapidly develop. Everyone that had been in that industry scaled back their development efforts.

None the less back in those early days, when we were thinking about how application interfaces would change when you have keyboard-less tablet machines, I developed the notion of 2D parsing. This was nothing other than a name that I had for a technology that I believed COULD be built though I had no idea of how to build it.

It occurred to me that there are many diagrammatic languages, things like math notation, music notation, architectural floor plans, flow charts, blue prints, electrical circuit diagrams, chemistry formulae - all things that are not particularly easy to input on a machine with a keyboard because they are primarily graphical (i.e. 2 dimensional) in nature. While these are hard to input with a keyboard, they can be fairly easy to scribble down on a napkin or a sheet of paper. What was needed was a way to recognize what you were doing when you drew a circuit diagram. You needed to recognize that this line was a way of connecting this point to that point and that this zig-zag line meant that you wanted a resistor here and so on. 

"Parsing" is the name of the step that you perform in a normal compiled computer language when you recognize the chunks of text that show up in source code for what they are: "Oh, that is a variable name, and this is an assignment statement, so that must be a function call." Parsing, as it is normally defined, is something that is done on a one dimensional stream of text, one character after another. I wanted to do the same sort of thing except that in a diagrammatic language you don't have that convenient feature of the one dimensional order of the characters. You might draw this something up here and then something else down there and then much later connect that upper thing to that lower thing. Yes, there is the order that the person drew the strokes but typically the structure of a diagram has nothing what so ever to do with the order that someone drew the components of that diagram.

As I said, back then in 1990 all I had was a name but no real idea of how I would implement any such thing. The idea languished.

Almost 15 years later, 2002, I once again had a chance to work on some software for a tablet machine. The company had produced a tablet machine for viewing sheet music and had some vague notion that it would be useful if they had some music notation software that would run on that machine. So I resurrected my notion that 2D parsing might be a useful notion and started working on ideas for a gesture based music notation application. That was not my primary job for the company, it was just a project I worked on in the background mostly for my own amusement.

I spent nearly two years trying out ideas and mostly discarding them until one day in 2005 I had an Ah-HA! moment, and saw a clean way to do the 2D parsing that I had wanted to do more than a decade ago. I threw out nearly all the code that I had written in the past two years, started from scratch and in 3 weeks of mad coding had a demo of a music notation app. This was just a demo. It would not Open files or Save files, but you could create complicated musical notation entirely with gestures as desired. However by that time the company's interest in music notation had wained and they were not interested in spending resources to complete the application, so once again development lapsed.

It was five years after building that music notation demo that Apple launched the iPad in 2010, a full two decades after I had first coined the notion of 2D parsing. 5 years after the launch of the iPad, in 2015, I still saw virtually no one building gesture aware applications. I keep waiting for someone else to do this work so that I don't have to publish it myself and it has yet (2021) to happen. So I finally gave up and decided that I will just have to explain how it is you can do this.

What we will build in this next project is NOT really a music notation application, or if we do build any music notation, we will build only parts of it, just enough to test/demonstrate the framework for the reaction architecture. This word "framework" is basically what we used to call a "library" though it is typically a little more focused than an entire library. I have mentioned the term "helper function" previously, a short little piece of code that saves you some work and makes it just a little easier to do something. Well, a "framework" is like a helper function on steroids. Instead of one or two helper functions it is dozens or hundreds that make it easier to build something.

There are many frameworks. JQuery is/was (things always change) a very popular Javascript framework that helps you create animated web pages. Swing is a framework that helps you build GUI programs. Few people write new computer languages, but lots of people build frameworks these days. The notion of Computer Language Design continues on in the development of frameworks. The framework that we will build to help us build gesture based applications is called the "Reaction Architecture".

Just so you have an idea of the scope/size of this course before we wade into it, the framework in an early design had twenty-eight classes. That is 28 classes of helper functions. That is the point of this course, to show you that your mind is not limited to understanding projects that have only one or two classes, you can have dozens or even hundreds of classes and still make sense of it all. In fact from my viewpoint that is the purpose of classes, they are file cabinets to hold and organize your stuff. It is time to look at organization from the standpoint of a system that is large enough that without that organization you would be lost. I can't honestly say that we will build all 28 in this one semester course - we will eventually run out of time. We will probably not finish, however we will build enough of this framwork for you to understand it and to be able to both use it for your own projects and to be able to extend it if you wish.

Just for the record, for those of you that are actually taking my one semester course and not just reading this online, my course meets 4 hours a week for about 10 weeks for a total of 40 hours. Technically that is ONE single week's work if you had a job (that would be one of those non-existant programming jobs where you only work 40 hour weeks instead of 50 or 60). And it actually took me 3 weeks to build my demo - of course, now that I KNOW what I am doing I can presumably avoid some of the dead ends. So the fact is that everything that we do in this one semester class COULD/SHOULD be done in a single week's work. IMHO It is actually EASIER to write this and get it all working if you do it all in a week instead of stringing it out slowly over 10 weeks. By week 9 you are already forgetting decisions that you made in week 2 - "Did class Foo extend Bar or did it just have a bar element in it?". As a manager of software developers I would have NO problem assigning this entire course as a one week project - go read that article, build all the code that they mentioned, and then we can start on the rest of the design.

Now, in this section, I have only mentioned the history of where this framework came from. In the next section I will start explaining what the reaction system will do and give you an idea of how it will do it.

[next: Reactions](MJ0302.md)